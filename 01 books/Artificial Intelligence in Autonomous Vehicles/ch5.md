## 5  
Autonomous Car Driver Assistance System

_<sup>1</sup>Department of CSE, R.M.K. Engineering College, Jeppiar Institute of Technology, Tamil Nadu, India_

_<sup>2</sup>Jeppiar Institute of Technology, Tamil Nadu, India_

_<sup>3</sup>Hindustan Institute of Technology and Science, Tamil Nadu, India_

_<sup>4</sup>RMK Engineering College, Tamil Nadu, India_

### _Abstract_

For the larger part of the last few decades, researchers have been actively pursuing their goals of developing automobiles that can operate without human intervention. Numerous studies have been carried out on the issue of using a camera that is positioned on the front of a vehicle for the purposes of localization and navigation of the vehicle, environment mapping, and obstacle avoidance. These are all goals that the camera is intended to accomplish. Every single algorithm for recognizing traffic signs has four primary objectives that it is striving toward accomplishing. These objectives are listed below. The algorithm includes a list of these objectives. The first and most important thing for us to do is to guarantee that the algorithm will provide reliable results. The fundamental concept of accuracy has to be adhered to throughout the whole process of assessing it, beginning with the methodology all the way up to the measurement that is employed. There is a good chance that the activation of driver assistance features will need nothing more than a high degree of accuracy when the settings are left at their defaults. On the other hand, accuracy in the worst-case situation has to be addressed in other contexts, such as the context of fully autonomous automobiles, and it needs to be tested adequately. This is something that needs to be done. This is an activity that absolutely must be carried out. An algorithm that can recognize traffic signs by their color and form has been created. This method is based on the detection of the signs’ colors and shapes. The creation of this algorithm has already taken place. The photographs used in the software were captured using a camera with a poor resolution that was attached to the windscreen of a moving automobile. These photographs were then used in the program. Then, these photographs were sent into the algorithm as its input. The capacity of two different forms of traffic indicators, namely, red stop signs and yellow warning signs, to offer an early warning to vehicles is evaluated, and the findings are collected. As a direct result of this, the technique of form-based detection is sensitive to the complexity of the backdrop, while the colorbased detection approach is sensitive to the lighting environment.

**_Keywords_:** Vehicle, environment mapping, and obstacle avoidance, accuracy, color based detection approach

## 5.1 Introduction

Over the course of the last few decades, one of the areas of study that has seen the most activity in the field of computer vision is that of automated driving assistance. This area of study has been one of the topics that has seen the highest activity. In recent years, there has been a growth in both the number of different modes of transportation and the overall amount of traffic. This has resulted in a significant rise in the complexity of coordinating logistics and the stress that is placed on society as a whole. It is anticipated that the introduction of driverless cars will result in a wide range of beneficial changes for society. One of these changes will be a reduction in the number of people who are killed or injured as a result of traffic accidents, or even the elimination of these occurrences entirely. Sixty percent of the time, drivers are to blame for accidents and injuries that are the direct result of road traffic \[[1](https://learning-oreilly-com.ezproxy.christchurchcitylibraries.com/library/view/artificial-intelligence-for/9781119847465/c01.xhtml#ref1)\]. Passengers are to blame for 20% of these incidents, and pedestrians are to blame for 20% of these incidents as well. Because of this, the driver assistance system for autonomous cars has to conform scrupulously to the rules that have been stipulated by the authorities in charge of traffic. These rules include those that apply to traffic signals, vehicle indicators, lane markings, vehicle speed, and traffic signs. Other regulations that fall under this category include those that govern the speed of vehicles.

As needed components, an automated driving assistance system has to be able to recognize hand gestures used by traffic police, recognize indications, and detect lane markings. Additionally, the system should be able to locate lane markings. The exchange of information and ideas that takes place between individuals is heavily reliant on the use of various hand gestures. The recognition of the gestures used by law enforcement officers in various traffic circumstances is the most important piece of information that can be gathered for autonomous driving in urban areas. This may be accomplished by watching police officers interact with various traffic scenarios. It is essential to keep an eye on the movement of other cars and to have an awareness of how the vehicles interact with one another in the many traffic conditions that may occur in order to drive in a manner that is both safe and efficient. Markings on the road, which are sometimes referred to as road marking instructions on occasion, present motorists with a variety of signals that may aid them in driving in a way that is safer.

The word “video,” which refers to still photographs that move, derives from the Latin word “videre,” which means “I see.” The term “video” refers to still photographs that move. Simply “I see” is the literal translation of the phrase “I see.” Video is a kind of recorded media that is distinguished by the transmission of a series of still pictures at a frame rate that is sufficiently quick to offer the illusion that the images are moving. This gives the impression that the images are progressing in time. Analog video tape formats include things like VHS and Betamax, while digital video formats include things like Blu-ray Disc, DVD, QuickTime, and MPEG-4. Blu-ray Disc, DVD, QuickTime, and MPEG-4 are examples of formats that may be used for digital video. Additionally, video may be created and conveyed _via_ the use of the three primary video standards. Each of these standards determines the maximum resolution of the display as well as the color palette that can be used. Any one of these standards may be used for the production and transmission of video. These three acronyms stand for three different technologies: Phase Alternating Line (PAL), Sequential Color with Memory (SECAM), and National Television System Committee (NTSC). SECAM was the first color television standard in Europe, and its data were stored on magnetic tape at the time. The PAL and NTSC television systems were both developed by the National Television System Committee. It is not conceivable for any one of them to coexist in the same location as the other one. It is not possible to play back video that was captured in one format using a different format. This is not something that is possible.

As a consequence of the debut of the Sony D-1 format in 1986, the year that marked the beginning of the commercial distribution of digital video, digital video has become more widespread. This digital movie is made up of a sequence of digital photographs that are shown one after the other in quick succession at a consistent rate. The tempo remains the same throughout the whole movie. The movie is rendered in digital format for the presentation. The individual still pictures that make up a video are referred to as “frames,” and the word “frame” is used when discussing a video. The number of photographs that are created in a single second is used as a yardstick to determine how often these images are updated. One second equals 33 frames (fps). Because of this, the number of still pictures that are formed throughout the course of a single second of video is referred to as the “frame rate,” and this is the meaning of the phrase “frame rate.” It might be as low as six or eight frames per second for older mechanical cameras, or it could be as high as more than 120 frames per second for more modern specialized cameras. Either way, the rate can vary greatly.

When a series of still pictures or digital images are strung together to create a moving picture or movie, each individual still photograph or digital image is referred to as a frame. A raster of pixels is utilized to construct each individual frame of a digital movie, and each frame is its own self-contained digital picture. A digital movie is composed of several distinct digital movies. If it has a width of w pixels and a height of h pixels, then the frame size, also known as the image size, is equal to w pixels times h pixels. In other words, the picture size is the same as the frame size. This is often referred to as the size of the image. The user’s needs will determine whether the digital picture is captured in color or in black-and-white mode, since both of these options are available to them. The value of each pixel in a grayscale picture is digitally represented using 8 bits, and the total number of levels in the image is 256. The total number of levels in an image is 256. It is possible for there to be anything between 0 and 255 levels in the picture. A color model is often used whenever the representation of an image that incorporates color is being done. The RGB values that are encoded using 24 bits per pixel are created by utilizing three unsigned integers of 8 bits each, ranging in value from 0 to 255. These values are then used to construct the pixel. The relative intensities of the colors red, green, and blue are represented by these three numbers (blue). Simply by combining the three main colors of red, green, and blue, a person is able to create any one of approximately 16 million distinct hues using only these three primary colors. The video of gray levels, denoted by the symbol “I,” can be described as “I = I1, I2,…, IM,” where “I1, I2,…, IM” refers to the sequence of gray-level photographs and “M” refers to the total number of frames that are included in the movie. The symbol “M” also denotes the total number of gray-level photographs. The letter “I” serves as a sign for the video of the gray level.

### 5.1.1 Traffic Video Surveillance

Over the course of the last several decades, the image processing community has shown a considerable level of interest in the subject of traffic video surveillance. Within the realm of computer vision, one of the most important research areas to focus on is the traffic video surveillance system. Its principal functions are to recognize objects, identify them, and follow their movements over a sequence of images. In addition to this, it makes an effort to grasp and make sense of the behavior of the things that are being observed. Analysis of the road’s state for the purpose of traffic video surveillance and safety warning is a task that involves expertise from a range of disciplines. These fields include, among others, computer science, robotic engineering, and psychology. A traffic video surveillance system is able to provide efficient and effective applications, some of which include commercial and public safety, visual surveillance and congestion analysis, human identification and the detection of anomalous behavior, and the monitoring of vehicles both inside and outside of cities, highways, bridges, and tunnels, among other places. One of the applications that a traffic video surveillance system is able to provide is the ability to provide efficient and effective applications.

Despite the significant progress that has been made in this area, the essential goal of developing a system that is both effective and reliable and that is also able to function normally under demanding real-time situations has not yet been achieved. This is an essential objective that must be achieved in order for the system to be considered successful. As a consequence of this, the objective of this research is to develop an intelligent driver assistance system in order to forestall the occurrence of accidents. There are two separate variants of the system that monitors and records a video of traffic, and these variants are as follows:

1.  A security system that is composed of cameras that are permanently installed
2.  A surveillance system that employs cameras that can pan and tilt

The primary goal of the surveillance system that makes use of stationary cameras is to investigate the capabilities of the system to watch and organize urban traffic in order to track traffic occurrences that might lead to accidents. This is done in order to track traffic events that might lead to accidents. The static images captured on the recorded movies are of a very good quality, and they might provide the security and police departments with important information if they are analyzed. These indications include things like the license plate of the automobile, the time it passed, the movement path it took, the driver’s face, and a variety of other details. The moving surveillance camera is permanently fixed in the vehicle, and it gives the driver access to a high-quality video feed of the surrounding traffic in addition to providing improved performance on the road.

In the course of this research endeavor, a stationary camera has been used as the tool of choice in order to pinpoint the precise position of various hand gestures employed by police officers. Methods using moving cameras are used for the purpose of identifying road lane markings and the indicating signals seen on the back of motor vehicles.

For a very long time, those who study computer science and robotics have harbored the dream of developing automobiles that can navigate their own routes without human intervention. Autonomous vehicles have the potential to bring a variety of benefits to the general public, including the removal of the need for drivers to pay attention to the road and the promotion of calm and safe driving. Currently, drivers are required to pay attention to the road at all times. It is the job of a driver assistance system to provide a driver with support and, as a result, the necessary information automatically to a person who is driving for the sake of the driver’s own safety, the safety of the vehicle he is operating, and the safety of the environment in which he is operating it. The average person in today’s society has a heightened understanding about the significance of the issue of road safety, which is a positive development. One of the most important aspects that contributes to safer driving is compliance with the many rules and regulations that govern traffic in India. It is very necessary to have a comprehensive awareness of the Indian traffic rules in order to reduce the likelihood of being involved in an accident. The following are the components of Indian traffic legislation that need to be taken into account:

-   The hand signals used by law enforcement personnel
-   The traffic light signals and signage along the route
-   Road signs and lane markings strategically placed along the roadway
-   The hand signal is used by drivers of motor vehicles.
-   Limits on the maximum speed that are legally allowed
-   Lights on the vehicle that show its state (taillight, brake light, indicator lights, and beam light)

### 5.1.2 Need for the Research Work

Traffic regulations have been enacted in every part of the world in order to regulate the ever-increasing number of automobiles on the road and to promote living and driving conditions that are safer. Each geographical location has its own set of rules and regulations regarding the laws that control transportation. People who have to drive for lengthy periods of time often feel distractions, exhaustion, and boredom in their driving. As a consequence of these elements, accidents happen rather often, and depending on the circumstances, they might even be fatal. As a direct consequence of this, the development of driverless automobiles is now the main focus of the majority of research being conducted today. The provision of automated driving assistance is the major role that an autonomous vehicle is expected to play. This body of research is being conducted with the intention of formulating a plan for an automated driver assistance system. This plan will serve as the basis for the development of completely autonomous vehicles that are capable of functioning in the Indian traffic environment. It focuses on the hand gestures employed by those who enforce traffic laws.

## 5.2 Related Work

Since that point in time up to the current day, there have been a great many different research groups researching on the topic. Using their own distinct approach, each of these organizations has looked for a way to resolve this problem in recent years. Despite the fact that, at first glance, the fundamental stages toward a solution seem to be extremely well outlined and uncomplicated, the specifics of the ways that have been employed reveal that there are a variety of possibilities and a great deal of concepts. At this moment, no one solution approach has distinguished itself as the undeniable leader, and it is quite evident that it will be quite some time before solutions begin to arrive on the market. The process of detecting the identification of a road sign involves a number of processes, the most important of which are the steps of detection and recognition. During the stage that is referred to as “detection,” the various research groups are split up into three main categories. The first set of researchers came to the conclusion that the colors of traffic signs are key bits of information that may be utilized to identify and categorize different traffic signals. The second school of thinking claims that it is feasible to recognize traffic signs based just on their shapes, but the third school of thought maintains that the combination of color and form is what creates what comprises the important component of any road sign identification system. As a result, there are three basic approaches to recognizing traffic signs: recognition based on the information supplied by color, recognition based on the information provided by shape, and recognition based on the information provided by both color and shape. The pictures that were used in all of the articles that were examined were ones that were taken from real-life traffic scenarios, and they were pretty similar to the photographs that were gathered for this research. When it comes to carrying out the task of traffic sign detection, the approaches that are used might vary greatly depending on the author. It is possible to find a solution to this issue by using any one of a wide variety of various strategies.

Baklouti _et al._ \[[6](https://learning-oreilly-com.ezproxy.christchurchcitylibraries.com/library/view/artificial-intelligence-for/9781119847465/c01.xhtml#ref6)\] used thresholding to separate pixels in a digital image into those that make up objects and those that make up the background. The approach consists of determining the distance in RGB space between the color of a pixel and a reference color in order to achieve the desired effect. This distance is measured relative to the color of the reference color. If the color of the unidentified pixel is sufficiently close to the color of the reference pixel, then the unidentified pixel will be considered an object pixel.

Nickel and Stiefelhagen \[[7](https://learning-oreilly-com.ezproxy.christchurchcitylibraries.com/library/view/artificial-intelligence-for/9781119847465/c01.xhtml#ref7)\] suggested the creation of an algorithm that would be able to recognize the traffic warning signs for Stop, Yield, and Do Not Enter. This would be a useful tool. It is made up of a total of six distinct modules, which include the following: color segmentation, edge localization, RGB differencing, edge detection, histogram extraction, and classification. The use of color segmentation is confined to the localization of red edge areas, the segmentation process itself is carried out in a sparse way, and the interpixel segmentation distance is determined.

Wu and Huang \[[8](https://learning-oreilly-com.ezproxy.christchurchcitylibraries.com/library/view/artificial-intelligence-for/9781119847465/c01.xhtml#ref8)\] came up with a method for discovering signs that may be of use to those who are blind or have some other kind of visual impairment. The author made the premise that signs are composed of two distinct colors—one for the sign itself and another for the text—and that sign limitations are specified in advance (rectangle, hexagonal). In order to locate regions relevant to a hypothesis, an algorithm for expanding regions is utilized, and inside this algorithm is a series of tests that pick seeds to serve as its starting point.

Corradini \[[9](https://learning-oreilly-com.ezproxy.christchurchcitylibraries.com/library/view/artificial-intelligence-for/9781119847465/c01.xhtml#ref9)\] proposed a method for determining the road sign’s identity that included making use of the sign’s color distribution while doing so within the framework of the XYZ color space. They created a color similarity map by using the color distribution, which was then included into the picture function of an active net model. The road sign \[[10](https://learning-oreilly-com.ezproxy.christchurchcitylibraries.com/library/view/artificial-intelligence-for/9781119847465/c01.xhtml#ref10)\] may still be freed from the muddle even if it becomes entangled in a functional net throughout the process.

Yoon and Kuijper \[[11](https://learning-oreilly-com.ezproxy.christchurchcitylibraries.com/library/view/artificial-intelligence-for/9781119847465/c01.xhtml#ref11)\] came up with a way to identify traffic signs by including the HSV and YUV color spaces into their algorithm. The system is brought online in two distinct stages one after the other. The first step of the process involves translating the RGB image into the YUV color space and then equalizing the histogram of the Y channel. The second stage involves creating a new RGB. This concludes the first step of the process. In the second stage, color segmentation is achieved by first converting the RGB picture that was produced in the first stage into the HSV and YUV color spaces and then applying a sufficient amount of threshold to the H and UV values. This sequence of steps is repeated until the desired results are obtained. This puts an end to the procedure. Following this, an AND operation is carried out, which combines the two results obtained before.

Stenger \[[12](https://learning-oreilly-com.ezproxy.christchurchcitylibraries.com/library/view/artificial-intelligence-for/9781119847465/c01.xhtml#ref12)\] developed a computer vision system that is capable of recognizing traffic signs and can be placed in a car. Stenger’s \[[12](https://learning-oreilly-com.ezproxy.christchurchcitylibraries.com/library/view/artificial-intelligence-for/9781119847465/c01.xhtml#ref12)\] technology can be used to help drivers stay safe on the road. Several tests, each employing a different kind of road sign, were carried out in order to explore the stability of colors when exposed to a wide range of lighting conditions. The goal of these investigations was to determine how colors changed over time. Segmentation is made possible by the use of the RGB color space. It has been shown that there are substantial disparities between the red, green, and blue components, and that these differences, when paired with an appropriate threshold, have the potential to be used for segmentation of the data.

## 5.3 Methodology

The vehicle-mounted cameras that are put on smart vehicles are the ones that record the pictures of the road traffic, and the goal of the traffic sign detection is to adequately extract the interested traffic sign areas from the photographs of the road traffic that are now available. However, the quality of the captured pictures might vary depending on the surrounding environment. In order to properly identify these qualities, it is necessary to follow the intrinsic properties of traffic signs, such as their color and form. Within this area, it is primarily composed of two components: traffic sign segmentation based on the color space and traffic sign recognition based on form attributes.

1.  Road lane mark detection as shown in [Figure 5.1](https://learning-oreilly-com.ezproxy.christchurchcitylibraries.com/library/view/artificial-intelligence-for/9781119847465/c01.xhtml#fig5-1).

### 5.3.1 Intelligent Driver Assistance System

The term “Intelligent Driver Assistance Systems” (IDAS) refers to systems that provide assistance to drivers of motor vehicles in order to increase both comfort and safety. This is achieved by presenting a display that is ergonomically appropriate for the environment in which the vehicle is operated and by sending a warning indicator in the event that any potentially dangerous situations are present in the traffic scenes that are located around the vehicle. The Driver Assistance System, also known as DAS, is intended to be of assistance to drivers of motor vehicles. It does this by transmitting signals, such as emergency braking systems and detecting indication lights, with the intention of alerting drivers to moving vehicles, the road, or any hidden threat. It is in the best interest of drivers to keep their attention on other moving vehicles, since doing so will reduce the amount of accidents that involve moving cars.

![[attachments/fig5-1.jpg]]

[**Figure 5.1**](https://learning-oreilly-com.ezproxy.christchurchcitylibraries.com/library/view/artificial-intelligence-for/9781119847465/c01.xhtml#rfig5-1) Aim of the proposed research.

Over 1.2 million people are murdered and an additional 50 million people are injured in road traffic accidents each year, as reported by the World Health Organization (WHO) \[[2](https://learning-oreilly-com.ezproxy.christchurchcitylibraries.com/library/view/artificial-intelligence-for/9781119847465/c01.xhtml#ref2)\]. As a result, one of the key priorities of governments and residents all over the world is to ensure that people who are traveling on roads do so in a safe manner. India has the highest number of road accidents of any nation in the world. This is mostly because of the ever-increasing number of automobiles that are driven on the country’s roads as well as the ever-increasing congestion levels. Advanced driver assistance systems are designed to make everyone in the vehicle, including the driver, safer by communicating information on the vehicle to the driver and the passengers in the vehicle.

Intelligent driver assistance systems incorporated a variety of technologies that enhanced safety, such as electric lighting, which made its debut in 1898 on the Columbia Electric car, and turn signal lights, which made their debut in 1907. Both of these innovations were integrated in the system. These two advancements came about as a result of efforts to make driving a safer activity. In the 1920s, medical experts first started campaigning for seat belts to be installed in cars as a method of protecting passengers from injury. In the 1960s, a group of researchers working together created the prototype for what would later become known as the airbag system. On the other hand, it took the United States and Europe an additional 20 and 30 years, respectively, to make it the industry standard. In 1978, Bosch and Mercedes-Benz were the first companies to make their antilock braking system (ABS) technology accessible to the general public on commercial cars.

Over the course of the last 15 years, researchers have made significant strides in developing an intelligent system that is able to anticipate potentially dangerous conditions and to make accurate predictions about accidents. They referred to it as an Advanced Driver Assistance System (ADAS), which means that it assists the driver in the sense that it provides warnings, aids in forming judgements, and even conducts autonomous evasive maneuvers when required in extreme situations. It differs from earlier generations of safety technology in that in addition to receiving mechanical or physical signals from the vehicle it is installed in, it is also capable, albeit to a lesser degree, of comprehending the environment outside the vehicle in which it is installed. The ADAS has a wide variety of applications, which include human machine interfaces, object identification, vehicle detection, tracking, and alert assistance. Other applications include human machine interfaces, object identification, and vehicle detection.

The year 1986 saw the development of an autonomous highway driving system by the group led by E. Dickmanns \[[3](https://learning-oreilly-com.ezproxy.christchurchcitylibraries.com/library/view/artificial-intelligence-for/9781119847465/c01.xhtml#ref3), [4](https://learning-oreilly-com.ezproxy.christchurchcitylibraries.com/library/view/artificial-intelligence-for/9781119847465/c01.xhtml#ref4)\], which marked the beginning of the field of ADAS. They exhibited a system that was capable of driving through obstructed streets at speeds of up to 59 miles per hour (96 km per hour) using cameras, simple image processors, and Kalman filtering. This system was shown to us. These days, a range of advanced driver assistance technologies have made their way into the commercial market and may be found in computer vision technology. Some of these technologies include automatic parking and lane departure warning systems. The use of this technology will make it possible to construct advanced driver assistance systems. Autonomous Driving System (IDAS) that makes use of traffic video surveillance to identify traffic police gestures, detect vehicle indication signals, and provide lane mark warning in traffic scenes system.

### 5.3.2 Traffic Police Hand Gesture Region Identification

The management of traffic on roadways is a challenging task that is receiving an increasing amount of assistance from automated technology. These kinds of systems are starting to appear more often. The formation of rules and regulations for traffic is done with the purpose of allowing the safe and orderly movement of motor vehicles along highways. This is the goal of the rules and regulations that are established. In addition, the rules and laws that govern traffic are not just meant for motorists who are driving vehicles on the road; they are also created for walkers, cyclists, motorcyclists, and any other people who utilize the road. The correct knowledge of traffic rules has the ability to reduce the number of accidents that take place and, as a consequence, to make it easier to establish a transportation system that is both secure and well-organized over the whole of our country \[[5](https://learning-oreilly-com.ezproxy.christchurchcitylibraries.com/library/view/artificial-intelligence-for/9781119847465/c01.xhtml#ref5)\].

In an environment where human body gestures are used for the purpose of controlling traffic, the drivers are obligated to follow the instructions that are given to them by the traffic police officer. In an effort to make driving a more secure endeavor for motorists, researchers are focusing their efforts on developing methods that can automatically recognize the hand signals used for traffic management. When this technology is utilized in combination with a traffic police control system, a human traffic controller is able to analyze the flow of traffic within a visual range around the traffic intersection. This range includes the area surrounding the intersection. The instructions for controlling traffic can be broken down into three distinct categories, which include “stop all cars on every road direction,” “stop all vehicles in front of and behind the traffic police officer,” and “stop all vehicles on the right and behind the traffic police officer.” Each of these categories contains specific instructions for controlling traffic. Each and every one of these hand signals for traffic is created by combining the arms pointing in a variety of different directions. There are a total of 12 distinct Indian traffic hand signals that may be constructed using the various control command types. The following table provides an explanation of each of the 12 hand signals that are used by the police during traffic stops.

The most significant obstacle that must be overcome in computer vision technology for human and traffic video surveillance is the development of a system for detecting and identifying gesture regions. This technology is able to recognize and pick up on a variety of different hand movements. The primary goal is to create hand gesture recognition that may be utilized in recordings of traffic police employees by making use of established ways for enforcing traffic police laws. These recordings might be used to improve traffic safety. In recent years, it has become more vital for members of the police force to be able to recognize hand signals. The increasing volume of traffic that may be seen on metropolitan streets is primarily responsible for this phenomenon. The purpose of this is to create a traffic surveillance system that makes use of computer vision techniques to recognize human beings, hand gesture regions, and hand gestures themselves in films that have been gathered specifically for the purpose of recognizing those hand gestures. This system will be built with the intention of recognizing those hand gestures. Recognizing such hand motions is the objective of this effort in the long run. [Table 5.1](https://learning-oreilly-com.ezproxy.christchurchcitylibraries.com/library/view/artificial-intelligence-for/9781119847465/c01.xhtml#tab5-1) shows the attributes of the Indian traffic police hand gestures. As a direct result of this, the primary purpose of this effort is to:

• Determine the identities of the individuals shown in the video sequences of the traffic police force that take place along the road traffic scenes.

[**Table 5.1**](https://learning-oreilly-com.ezproxy.christchurchcitylibraries.com/library/view/artificial-intelligence-for/9781119847465/c01.xhtml#rtab5-1) Indian traffic police hand gestures.

| **_A_<sub>1</sub>, _A_<sub>2</sub>, _A_<sub>12</sub>** | **Hand gesture action meaning** |
| --- | --- |
| A1 | To start one side of vehicles |
| A2 | To stop vehicles coming from front |
| A3 | To stop vehicles approaching from back |
| A4 | To stop vehicles approaching simultaneously from front and back |
|   |   |
| A5 | To stop vehicles approaching simultaneously from right and left |
| A6 | To start vehicles approaching from left |
| A7 | To start vehicles coming from right |
| A8 | To change sign |
| A9 | To start one side of vehicles |
| A10 | To start vehicles on T-point |
| A11 | To give VIP salute |
| A12 | To manage vehicles on T-point |

Naturalistic and intuitive human hand gesture has been a great motivating factor for researchers to put their efforts in research and develop the most promising means of interaction between humans and computers. Researchers have put their efforts in research and developed the most promising means of interaction between humans and computers. The most promising techniques of interaction between people and computers have been established—thanks to the efforts of researchers who invested their time and energy into study. Through the investigation and creation of novel approaches, researchers have been concentrating their efforts on the establishment of the most productive ways for humans and computers to connect with one another. To be more precise, the many various kinds of gestures are of immense aid in reflecting the many different communication signals that are necessary to complete particular jobs. This is due to the fact that different tasks require different communication signals. As a result of this, the various types of gestures are an especially valuable tool for communicating with one another. As a direct result of this, the second objective of this body of work is to make use of computer vision technology that has been created from dynamic gesture movement in order to partition the hand gesture area of traffic police laws.

Despite the fact that there may be a number of different components present, the motion of gestures will be considered to comprise all of the relevant local information relative to the location of the gesture. The ability to comprehend the motion of the gesture is the single most important ability that one must possess in order to recognize the hand laws that are utilized by traffic police. Therefore, the end goal of the approach is to extract from the area of the human gesture that has been subdivided into the components that will allow the machine to comprehend the significance of that motion.

This procedure takes place during the evaluation of the gesture identification. The investigation that has been carried out on the subject of pattern classification has resulted in the production of a variety of distinct instances of typical classifiers. Support Vector Machines (SVM), Decision Trees, Random Forests, and Naive Bayes are some examples of these types of models. As a direct result of this, the ultimate goal for the gesture recognition system is to choose the classification model and then include the recovered features into the classifier that is used by the system.

The recognition of human hand gestures is the most difficult job involved in the processing of videos. This is due to the fact that it enables the computer to detect, recognize, and comprehend the hand gestures of the user in order to communicate with a diverse selection of human machine interfaces. This is the primary reason why it is of such great value. The gesture action of traffic police is a vital communication tool for ensuring that drivers are able to operate their cars in a safe manner while dealing with difficulties with traffic. The goal of gesture recognition is to categorize the myriad of action rules that are associated with gestures, then assign those categories names that have some kind of connotation associated with them. The following is a summary of the primary issues that are encountered by the gesture recognition systems that are used by the traffic police within the setting of the environment of the traffic:

Acquiring Information With a Camera: In an urban setting, a fixed camera is positioned at a busy intersection in order to collect videos. These videos are collected utilizing the camera. All of the action that takes place there is recorded by this camera at all times. The computer vision technology is able to separate out particular personnel of the law enforcement agency who are present in a traffic video scenario. This is possible even when the backdrop is always changing. This is done in a myriad of various settings and circumstances.

![[attachments/fig5-2.jpg]]

[**Figure 5.2**](https://learning-oreilly-com.ezproxy.christchurchcitylibraries.com/library/view/artificial-intelligence-for/9781119847465/c01.xhtml#rfig5-2) Challenges for gesture rule recognition.

Transformation of Gesture: A gesture may be articulated within a human’s hands, arms, or body; it can also be the movement of a person’s head, face, or eyes, such as winking, nodding, or rolling the eyes. Gestures can also be expressed within a human’s hands, arms, or body. It is also possible for a gesture to be articulated within the hands, arms, or body of a human being; a gesture can also be articulated within the hands, arms, or body of a human being. Animals are also capable of expressing motions on the inside of their bodies. When it comes to situations involving traffic, it is exceedingly challenging to discern the movement of the human body from the movement of the gesture due to the dynamic gesture activity that occurs in these kinds of conditions.

Recognition Is Done Through Gesture in Indian Culture: The rules that traffic police employ to communicate through gestures have a profound impact on the manner in which drivers are expected to interact with one another. The traffic regulations themselves are varied, as can be shown in [Figure 5.2](https://learning-oreilly-com.ezproxy.christchurchcitylibraries.com/library/view/artificial-intelligence-for/9781119847465/c01.xhtml#fig5-2), despite the fact that the rotation of the hand signals used by traffic police is identical to one another. The inability to recognize traffic gesture norms that are reasonably consistent across a number of traffic conditions is the primary obstacle that has to be overcome. There are many different traffic scenarios.

### 5.3.3 Vehicle Brake and Indicator Light Identification

Research into autonomous vehicle systems has been one of the sectors with the greatest rate of recent increase in recent years. This may be attributed to the vital part it plays in maintaining the safety of drivers. It is vital to keep an eye on the behavior of other vehicles and to have a strong grasp of how they interact with one another in typical traffic scenarios in order to drive in a way that is both safe and successful. During the course of this project, videos will be shot inside the automobile with the assistance of a camera that will be left inside permanently. In situations involving road traffic, the characters in these movies get important information about the driving car in front of them. The brake light, the indicator on the left side of the vehicle, and the indicator on the right side of the car are the three kinds of automotive lights that drivers use the most often. In the framework of the traffic environment, the vehicle that is following behind is expected to heed the instruction of the front moving vehicle lights. This is the case whether or not the lights are activated.

Numerous important particulars, such as the license plate number, the vehicle symbol, and the vehicle’s lights, are often shown on the trunk or trunk lid of a car. As can be seen in the figure, the logo of a vehicle and the license plate of the car both have the potential to supply information that may be utilized for confirming and identifying the vehicle.

Red is the color that is used for each of the indicator lights that are seen on a car, and each one has its own particular look. For instance, the left and right indicators on a vehicle that turns have a different design from the brake light that is seen on a vehicle that stops. The lights of a vehicle are positioned in such a way that they are centered on the left and right corners of the vehicle, as can be seen in [Figure 5.3](https://learning-oreilly-com.ezproxy.christchurchcitylibraries.com/library/view/artificial-intelligence-for/9781119847465/c01.xhtml#fig5-3). The detection of automobile brakes and indicators is essential for maintaining a safe driving environment, and the work that is being presented here demonstrates a novel approach to completing the job at hand.

![[attachments/fig5-3.jpg]]

[**Figure 5.3**](https://learning-oreilly-com.ezproxy.christchurchcitylibraries.com/library/view/artificial-intelligence-for/9781119847465/c01.xhtml#rfig5-3) Vehicle features.

It is of the highest significance to reliably and accurately recognize front moving vehicle signs such as turn signals and brake lights, especially for applications that depend on vision for traffic surveillance. The increasing number of vehicles adds to a range of challenges, including those relating to traffic control and management, issues with parking, accident rates, and a variety of other concerns. This is done so that computer methods can be used to construct a traffic surveillance system that is able to recognize vehicles and vehicle signals, as well as perform tracking and recognition in a video sequence that has been captured. The reason for this is so that computer methods can be used to construct a traffic surveillance system. As a consequence of this, the major goal of the work that is being proposed is to recognize the vehicles that are existing in the road environment throughout the whole of the traffic video sequences.

It is quite important for a vehicle to be equipped with a driver assistance system that can read out light indicators while the vehicle is in motion. Within the realm of computer vision technique, color segmentation is a frequent strategy that is used. As a consequence of this, the second objective of this body of work is to segment the vehicle lights using a color segmentation technique and locate the vehicle light zones within the car.

A video sequence displaying an automobile offers an explanation of a distinct indicator at each and every frame of the series. These indicators may be observed under a variety of different traffic circumstances. When it comes to autonomous driving, correct identification and continuous transmission of the light information from the car are necessary. As a consequence of this, the third objective is to develop an algorithm for monitoring automobiles that is able to get data on brake and turn signal functionality.

It has been shown by a large number of academics that the area of the development of automated techniques for the extraction of video characteristics is a subject that is booming. Therefore, the fourth objective is to extract novel and useful elements from each snapshot of a vehicle so that a representation of how the car’s lights are may be produced.

In conclusion, identification algorithms are very dependent on the plethora of light properties that the vehicle has. A large range of conventional classifiers may be found in the research that has been done on pattern classification. As a consequence of this, the ultimate objective of the work that has been described is to figure out which classifier model will be able to recognize the vehicle’s brake and indicator lights.

When you are behind the wheel of a car on the highway, it can be a challenging task to keep an eye on the brake and indicator lights. This is because there are a number of factors that can affect how you see them, including changes in the background, the amount of lighting, and the location of the car. It is of the highest significance to monitor and categorize the numerous indicator lights that occur in the traffic video sequences. These lights serve as a warning signal to assist in the prevention of future collisions, thus monitoring and categorizing these lights are essential. The summary that follows provides an overview of a few of the difficulties that are associated with the vehicle light identification system.

-   Camera Acquisition: This portion of the training consists of a moving camera that is stationed at a highway traffic scene. During this part of the class, records are obtained by the camera. In the video that was taken, the automobile would seem to be going very rapidly, which would explain why the picture from the camera is hazy.
-   Vehicle Position: The movies that were acquired were obtained when the cars were positioned in highway traffic situations. This is shown by the fact that the movies were captured. When driving on the highway, you may encounter a large number of automobiles moving in a variety of directions, as well as other objects and people that may pass you by. In light of this fact, it may be challenging to recognize a particular vehicle in a scenario such as the one that we are in right now.
-   It is possible that certain video sequences will include moving cars and other objects in the background. These compiled video sequences could include moving automobiles or other things in the backdrop at varied distances, which adds an extra level of difficulty.
-   Variations in Lighting: It is possible that the backdrop model will not be able to adjust to the subtle variations in lighting that occur throughout some of the traffic scenarios.

![[attachments/fig5-4.jpg]]

[**Figure 5.4**](https://learning-oreilly-com.ezproxy.christchurchcitylibraries.com/library/view/artificial-intelligence-for/9781119847465/c01.xhtml#rfig5-4) Challenges for vehicle light detection.

Vehicle Color: If the vehicle is red in color, then determining the vehicle brake and indicator light is difficult as shown in [Figure 5.4](https://learning-oreilly-com.ezproxy.christchurchcitylibraries.com/library/view/artificial-intelligence-for/9781119847465/c01.xhtml#fig5-4).

## 5.4 Results and Analysis

The navigable zone of a road is often found in the space in between the lanes of a road. This is especially true in the context of highway settings; hence, road lane-marking and direction are essential components of autonomous navigation. The phrase “road network” may refer to either the actual infrastructure of roads or the many control systems that are in place for motor vehicle travel. Accidents that are caused by traffic difficulties are becoming more common in today’s world as a result of the rising number of cars on the road and drivers who disregard the regulations that govern safe driving practices. In the past, accidents that were caused by traffic difficulties were much less common. The lane lines on the road may be the major or only indication that enables a driver to go safely in situations such as dense fog, mist, or when the warning lights of an approaching car cause the driver to lose his or her vision. The basic objectives of the driver assistance system are the lane departure warning system (LDWS), road lane-mark recognition, the lane change assistance system (LCAS), and the Lane Maintaining System (LMS). Road markings and instructions on road markers may have a range of different connotations based on where they are situated on the road. [Figure 5.5](https://learning-oreilly-com.ezproxy.christchurchcitylibraries.com/library/view/artificial-intelligence-for/9781119847465/c01.xhtml#fig5-5) provides an illustration of the key meanings that lie behind the different road signs. If you want to drive in a manner that is not only successful but also safe, it is vital to pay attention to the lane lines on the road and understand how they interact with one another.

When it comes to the creation of a driver assistance system, the classification of lane markings is one of the most important aspects that must be taken into consideration. Because the primary goal of the proposed method is to classify road lane markings, such as road area extraction and lane mark region recognition, the characteristics need to be more resistant to the variety of the road environment. This is because the method’s major objective is to classify road lane markings. When a vehicle is traveling in front of another vehicle, the region of the road that the vehicle is traveling on is always positioned in front of the vehicle and is not too far away from the car at that moment \[[9](https://learning-oreilly-com.ezproxy.christchurchcitylibraries.com/library/view/artificial-intelligence-for/9781119847465/c01.xhtml#ref9)\]. It really should not come as a surprise that the information available at the roadside sites is more extensive. As a consequence of this, the primary objective of this body of work is to make use of the region of interest (ROI) technique in order to discover and extract road area from the road environment.

![[attachments/fig5-5.jpg]]

[**Figure 5.5**](https://learning-oreilly-com.ezproxy.christchurchcitylibraries.com/library/view/artificial-intelligence-for/9781119847465/c01.xhtml#rfig5-5) Road markings along the road.

It is vital to have an accurate portrayal, identification, and classification of the lane marking information before continuing with the analysis. This is required in order to go forward with the process. As a consequence of this, the second objective is to identify the lane marking and identify it from the other areas of the road.

A road feature may be used to record the lane marking in traffic video sequences, which is a useful source of information \[[10](https://learning-oreilly-com.ezproxy.christchurchcitylibraries.com/library/view/artificial-intelligence-for/9781119847465/c01.xhtml#ref10)\]. This can be done with the help of a camera. According to this school of thought, a feature may be seen as an expressive component that is derived from the lane markers. As a consequence of this, the third objective is to extract lane marking elements from each photograph of a road area so that a representation of lane markers may be created.

Numerous academics have shown that the creation of an automated system for assigning a category to a video sequence is a vibrant topic of research, and they have done it in a variety of ways. Many of the conventional classifiers, such as SVM and hidden Markov model (HMM), have been developed as a result of the research that has been carried out on video classification (HMM). As a consequence of this, the final objective is to choose the classification model and determine the kind of lane markings and directions to use.

One of the fundamental building blocks of autonomous vehicle navigation is the categorization of the numerous lane markers that appear on the road. In a perfect world, the lines delineating the lanes of traffic would be white, and the pavement would be black. When identifying lanes that have markings, the following factors need to be thought about and taken into account.

-   A state of variable lighting may be present, in which the level of illumination of the surrounding road environment varies depending on factors such as the time of day \[[11](https://learning-oreilly-com.ezproxy.christchurchcitylibraries.com/library/view/artificial-intelligence-for/9781119847465/c01.xhtml#ref11)\], the weather, and the presence or absence of shadows. This type of lighting can be dangerous for drivers because it makes it more difficult to judge distances on the road. It is possible that this will have an impact on the quality of the video sequences that are captured \[[12](https://learning-oreilly-com.ezproxy.christchurchcitylibraries.com/library/view/artificial-intelligence-for/9781119847465/c01.xhtml#ref12)\]. [Figure 5.6](https://learning-oreilly-com.ezproxy.christchurchcitylibraries.com/library/view/artificial-intelligence-for/9781119847465/c01.xhtml#fig5-6) illustrates the impact that shadow has on the legibility of road lane markers.

Extremely low levels of lighting: The video sequences that were captured had extremely low levels of illumination, and the winding road surface is especially difficult to control. [Figure 5.7](https://learning-oreilly-com.ezproxy.christchurchcitylibraries.com/library/view/artificial-intelligence-for/9781119847465/c01.xhtml#fig5-7) illustrates how improper illumination might affect the visibility of road lane markers.

![[attachments/fig5-6.jpg]]

[**Figure 5.6**](https://learning-oreilly-com.ezproxy.christchurchcitylibraries.com/library/view/artificial-intelligence-for/9781119847465/c01.xhtml#rfig5-6) Road lane marks affected by shadow.

![[attachments/fig5-7.jpg]]

[**Figure 5.7**](https://learning-oreilly-com.ezproxy.christchurchcitylibraries.com/library/view/artificial-intelligence-for/9781119847465/c01.xhtml#rfig5-7) Road lane marks affected by low illumination.

## 5.5 Conclusion

The goal of the work that is now being done in this research project is to create an autonomous vehicle system with the intention of achieving effective detection and identification of traffic video sequences. This is the aim of the work that is currently being done. By using this approach, we were able to resolve the issues listed below.

Recognition of Hand Gestures for Law Enforcement Use in Traffic: The purpose of the research that is going to be given is to find a solution to the issue of gesture recognition for traffic rules that are being shown in a video sequence. It may be difficult to recognize a human person \[[13](https://learning-oreilly-com.ezproxy.christchurchcitylibraries.com/library/view/artificial-intelligence-for/9781119847465/c01.xhtml#ref13)\] in a video sequence due to the intricacy of the human body \[[13](https://learning-oreilly-com.ezproxy.christchurchcitylibraries.com/library/view/artificial-intelligence-for/9781119847465/c01.xhtml#ref13)\]. This study makes use of information related to gesture areas in order to construct a system that is capable of recognizing gesture movements. This is done because of the significant part that gestures play in the functioning of the human body. When there is a lot of traffic, for instance, a driver will watch a traffic police officer carefully since the information that is sent by the officer’s gestures is the most crucial. As a result of this, the work that has been done up to this point to create a gesture rules recognition system for use by traffic police contains the following steps:

-   Identification of human beings
-   Division of the gesture area used by the police in traffic situations
-   The extraction of cumulative block intensity characteristics from the portion of the gesture area that is traveling in a certain direction
-   Familiarity with the hand signals used by the Indian police in traffic situations

Vehicle Detection and Vehicle Indicator Recognition: The work that is being recommended addresses the challenges of vehicle detection and vehicle light tracking for autonomous cars by analyzing traffic video sequences. This is done in order to improve safety and efficiency. It is a challenging challenge to correctly categorize moving cars when the environment around the traffic scene is so complex. In addition to this, the split of the vehicle’s lights is still another significant characteristic that sticks out among the other components of the automobiles. The automated vehicle light tracking system is a very engaging system because of the fact that moving vehicles exhibit \[[14](https://learning-oreilly-com.ezproxy.christchurchcitylibraries.com/library/view/artificial-intelligence-for/9781119847465/c01.xhtml#ref14)\] a range of braking and indicator lights. As a consequence of this, the work that is being given offers a method for recognizing the indicator and brake lights that are seen on automobiles.

The Different Types of Road Lane Markings and Their Classification \[[15](https://learning-oreilly-com.ezproxy.christchurchcitylibraries.com/library/view/artificial-intelligence-for/9781119847465/c01.xhtml#ref15)\]: The topic of investigation for the research that has been proposed is the identification and classification of road lane markers for use in intelligent transportation systems. The removal of noise from the road environment is an extremely significant step due to the presence of noise in the road environment. Depending on the condition of the road, it may be difficult to recognize the lane markers. As a consequence of this, the classification of lane marking and lane marking direction in a video sequence works toward the following aims in order to accomplish them:

-   Road area extraction
-   The delineation of road lanes for identification purposes
-   Extracting attributes from the road’s lane markings in order to improve driving safety
-   Developing a method for the organization of road lane markings and the directions of lane marker

## References

1.  1\. Hussain, T., Shu, L., Sosorburan, T., Adji, A.S., Khan, A.H., Raja, A.F., Road traffic accidents: An observational and analytical study exploring the hidden truths in pakistan and south east asian countries. _Healthline_, 2, 1, 52–7, 2011.
2.  2\. Peden, M. _et al._, _World report on road traffic injury prevention_, WHO and UNICEF, London, 2004.
3.  3\. Dickmanns, E.D. and Zapp, A., A curvature-based scheme for improving road vehicle guidance by computer vision, in: _Cambridge Symposium Intelligent Robotics Systems_, International Society for Optics and Photonics, pp. 161–168, 1987.
4.  4\. Vlacic, L., Parent, M., Harashima, F., _Intelligent vehicle technologies: Theory and applications_, Butterworth-Heinemann, Australia, 2001.
5.  5\. Fang, G., Gao, W., Zhao, D., Large-vocabulary continuous sign language recognition based on transition-movement models. _Syst. Man Cybern. Part A: Syst. Humans, IEEE Trans._, 37, 1, 1–9, 2007.
6.  6\. Baklouti, M., Monacelli, E., Guitteny, V., Couvet, S., Intelligent assistive exoskeleton with vision based interface, in: _Smart Homes and Health Telematics_, pp. 123–135, Springer, 2008.
7.  7\. Nickel, K. and Stiefelhagen, R., Visual recognition of pointing gestures for human–robot interaction. _Image Vis. Comput._, 25, 12, 1875–1884, 2007.
8.  8\. Wu, Y. and Huang, T.S., Hand modeling, analysis and recognition. _Signal Process. Mag._, 18, 3, 51–60, 2001.
9.  9\. Corradini, A., Real-time gesture recognition by means of hybrid recognizers, in: _Gesture and Sign Language in Human-Computer Interaction_, pp. 34–47, Springer, Paris, 2001.
10.  10\. Le, Q.K., Pham, C.H., Le, T.H., Road traffic control gesture recognition using depth images. _IEIE Trans. Smart Process. & Comput._, 1, 1, 1–7, 2012. 135.
11.  11\. Yoon, S.M. and Kuijper, A., Human action recognition using segmented skeletal features, in: _Pattern Recognition (ICPR), 2010 20th International Conference_, pp. 3740–3743, IEEE, 2010.
12.  12\. Stenger, B., Template-based hand pose recognition using multiple cues, in: _Computer Vision–ACCV 2006_, pp. 551–560, Springer, London, 2006.
13.  13\. Dong, G., Yan, Y., Xie, M., Vision-based hand gesture recognition for human-vehicle interaction. _Proc. Int. Conf. Control, Autom. Comput. Vision_, 1, 12, 151–155, 1998.
14.  14\. Zabulis, X., Baltzakis, H., Argyros, A., Vision-based hand gesture recognition for human-computer interaction, in: _The Universal Access Handbook_, pp. 34–1, LEA, USA, 2009.
15.  15\. Kim, C.-H. and Yi, J.-H., An optimal chrominance plane in the rgb color space for skin color segmentation. _Int. J. Inf. Technol._, 12, 7, 73–81, 2006.

## Note

1.  [\*](https://learning-oreilly-com.ezproxy.christchurchcitylibraries.com/library/view/artificial-intelligence-for/9781119847465/c01.xhtml#rcor1)_Corresponding author_: [nbp.cse@rmkec.ac.in](mailto:nbp.cse@rmkec.ac.in)
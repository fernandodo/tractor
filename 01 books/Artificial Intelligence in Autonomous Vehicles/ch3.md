_Department of Computer Science and Business Systems, Thiagarajar College of Engineering, Madurai, Tamil Nadu, India_

### _Abstract_

Throughout the last decades, the number of vehicles on the road has steadily increased due to the rising demand for urban mobility and contemporary logistics. Two of the many detrimental effects of more vehicles on the road, which also impede economic development, are increased traffic congestion and traffic accidents. The issues mentioned above can be significantly resolved by making vehicles smarter by reducing their reliance on humans. Over the past century, various nations have conducted extensive research that has fueled the automation of road vehicles. The development of autonomous vehicle (AV) technologies is currently being pursued by all significant motor manufacturers worldwide. Undoubtedly, the widespread use of autonomous cars is more imminent than we realize given the development of artificial intelligence (AI). In order for AVs to perceive their surroundings and make the right decisions in real time, AI has emerged as a crucial component. This development of AI is being driven by the growth of big data from numerous sensing devices and cutting-edge computing resources. We must first examine AI’s development and history in order to comprehend its functions in AV systems.

**_Keywords_:** Artificial intelligence, autonomous driving system, LiDAR, ADAS, center prediction neural network, CNN, AV

## 3.1 Introduction

The development of communication and robotics has had a significant impact on our daily lives, especially transportation. The advancement of autonomous vehicle (AV) technology has been made possible by these breakthroughs. As sensory-based beings, humans use object recognition as a part of daily life. The future of cars is computer-based object recognition. The transition from manual object recognition to automated object recognition is a significant one. Thousands of automobile traffic and collisions in contemporary cities mostly as a result of human error cause unending annoyance as well as significant loss of life, property, and productivity. Automobiles can be fully automated so that no human involvement is necessary as a way to mitigate this. Fuel efficiency, comfort, and convenience are additional benefits of autonomous vehicles. The greatest benefit to a self-driving society is the elimination of driver error. Driver error, which accounts for over 90% of all crashes, is the leading cause of the more than 31,000 fatal auto accidents that occur each year in the United States alone. According to the Eno Center for Transportation, there would be a reduction in collisions of over 4 million, a saving of over a hundred billion dollars, and a saving of 21,000 deaths annually if 90% of the vehicles on American roads were self-driving. Recent significant advances in artificial intelligence (AI), along with cutting-edge data collection and processing technologies, are what are propelling AV research to new heights. AVs have received a lot of attention recently due to their rapid development. The magnitude of success of AVs depends on the better obstacle-detecting sensors and AI that paves the way for their incorporation. A computer uses artificial intelligence in a similar way to how a human would. AIs in AV development have been greatly influenced by the success of AI in many complex applications such as predictive analytics to validate the need for surgery. In particular, the development of deep learning (DL) has made it possible for numerous studies to address complexities in the field of autonomous vehicles, which are precisely identifying and locating obstacles on roads, making the right decisions at the right time like controlling the speed and direction of movement of the vehicle, etc. Fuzzy logic, the computing method where the bases of decisions are based on degrees of truth rather than the standard true or false Boolean logic and artificial neural networks (ANNs), and systems of computation modeled after the biological neural networks that make up animal brains are two of the many AI techniques used. Nowadays, a variety of passive and active sensors, including those that record the subsequent echo similar to that of a LiDAR, RADAR, Global Navigation Satellite System (GNSS), cameras, and GPS sensors, can be integrated extensively in autonomous vehicles. Laser light is used by LiDAR sensors to illuminate its surroundings. The time delay or interval is measured after this light is reflected. This aids in building 3-dimensional images of its surroundings. The altitude, latitude, and longitude information provided by the position sensors like GNSS and GPS allows the car to be precisely located on a map for navigational purposes. Microwaves or radio waves are used by radar systems to measure an obstacle’s speed, direction, and distance from the autonomous vehicle. The reflected wave is picked up by the transmitter after the waves are reflected or bounced off. At the site of the transmitter, the reflected wave is picked up after the waves are reflected or bounced off. Using information from the aforementioned cameras, sensors, geolocation sensors, maps, navigation programming, and systems for connecting with other autonomous vehicles, software combined with AI process the amassed data and orchestrate the mechanical operations of the automobile. These techniques mimic the extraordinarily challenging effort that human drivers undertake when they have to monitor the road, the vehicle, and themselves in order to drive.

The idea of driverless automobiles has been in existence for a while, but their prohibitive costs have prevented their widespread production. The AV concept has advanced to previously unheard-of levels—thanks to rapid research and development activities over the past 10 years. This is due to the fact that a wide range of stakeholders, such as transit agencies, IT oligopolies, transportation networking firms, automakers, chip and semiconductor producers, and others, have made large investments in and pushed these improvements. The necessity to tend to the geriatric population in developed countries and the rapid advancement of communication technology may have made AVs essential to business operations \[[1](https://learning-oreilly-com.ezproxy.christchurchcitylibraries.com/library/view/artificial-intelligence-for/9781119847465/c01.xhtml#ref1)\]. By 2040, these are anticipated to overtake an overall half the amount of the total vehicle sales and 40% of the travels, according to a forecast based on automatic transmission technologies or hybrid vehicle deployment and adoption of prior smart vehicles \[[2](https://learning-oreilly-com.ezproxy.christchurchcitylibraries.com/library/view/artificial-intelligence-for/9781119847465/c01.xhtml#ref2)\]. AV is associated with many beneficial societal effects, including safety during transport, reduced travel costs, and some mobility for people with limited mobility and those living in low-income families. Recently, it was predicted that, by 2025, about 1.9 trillion dollars of annual direct societal value will be produced \[[3](https://learning-oreilly-com.ezproxy.christchurchcitylibraries.com/library/view/artificial-intelligence-for/9781119847465/c01.xhtml#ref3)\]. These advantageous effects are what propelled the development of AV technology and will continue to do so in the long run.

Autonomous vehicles should be taken into account when planning transportation in the future though, as they are likely to have a big impact on how people travel and how the road system functions. In this chapter, we will discuss the past and current state of affairs with regard to autonomous vehicles and their potential effects on transportation in the future.

## 3.2 Role of AI in Driverless Cars

### 3.2.1 What is Artificial Intelligence?

The term “artificial intelligence” was first used in 1955 by computer scientist John McCarthy. The ability for cognition, learning, and decision-making in a computer program or machine is known as artificial intelligence (AI). The phrase generally refers to a machine that mimics human intelligence. AI allows us to program machines and computer programs to perform human-like tasks. These programs and machines receive a tremendous amount of data from us, which are then evaluated and processed so that they can act like humans and think logically. Automating commonplace human jobs is just the tip of AI’s iceberg; potential uses include driverless vehicles and life-saving diagnostic medical tools. Reactive machines, limited memory, theory of mind, and self-awareness are the four different categories of AI.

Reactive machines, the most basic type of AI, neither have the capacity for memory nor are able to recall the past or draw inferences from it in order to render judgments today. IBM’s Deep Blue supercomputer that can play chess can be considered one of the best examples of this kind of variety of AI system, which back in early 1997 beat the grandmaster of chess. This type of cognition involves the computer actively studying the outside environment and reacting in accordance with its observations that is not influenced by any personal ideology. Rodney Brooks, an Australian AI expert, argued that, in contrast to what is often assumed in the domain of AI, we are not particularly adept in modeling realistic computer simulations.

The second type is capable of gazing backward. AVs have already incorporated some of this. For instance, they keep an eye on the pace and direction of other cars on the road. It takes time and persistence to attain it; it requires identifying specific things and persistent monitoring of them. This is then incorporated to the previously preprogrammed world models the AVs possess, which also contain lane markings, traffic signals, and a few other important aspects, including bends in the road. To avert a breach in driving etiquette or being hit by passing cars or vehicles, they are taken into account while determining when to switch lanes by the vehicle. However, these basic tidbits of historical knowledge are not permanent. The automobile cannot learn from them, since they are not saved in the same way that years of driving experience help human drivers become better drivers.

The third type could be chosen as the defining distinction between the machines of current generation and those that will be developed in the upcoming years. Increased clarity is preferred when discussing the types of representations that machines must produce and the subjects of such depictions. The following more complex category of machines generates depictions of not only the environment but also other agents or entities that inhabit it. The “theory of mind” is a psychological phrase used to support the idea that humans, animals, and other beings can all have the ability to think and feelings that affect one’s behavior in either a direct or an indirect manner.

Self-awareness is the final stage in the AI development phase. Finally, AI researchers will have to develop intelligent machines that are potentially capable of understanding the abovementioned environment in which it is being deployed. This is sort of a continuation of the “theory of mind” that the AIs in this level possess. The term “self-awareness” is another name for consciousness. Conscious beings are aware of who they are, are aware of how they are feeling internally, and can anticipate how others are feeling. We naturally believe that everyone who honks at us in traffic is furious or irritated because we have a similar feeling when we honk at others. Without a theory of mind, such conclusions would not be conceivable.

### 3.2.2 What are Autonomous Vehicles?

The main feature of AI in interpreting its surroundings enables or gives way to a type of independent functional vehicle that is automated, the autonomous vehicle, to drive itself and carry out necessary actions without human interaction or assistance. The fully automated driving system allows the AV to make decisions in complicated situations as a human driver would. The independent operational driverless cars are the most automated ones standing in the level of at most 6; hence, it can be said that as the degree increases, so does the sophistication and its operations.

The basic-level car/vehicle is completely human-driven and has zero operational control. The movement of the car is directed by the driver. For instance, one must manually control the vehicle’s speed, use the brakes, and judge when to halt. This holds true for cars that include features like traditional cruise control systems that have to be manually set or adjusted in order to work.

Advanced driver assistance system (ADAS) in the AV can assist the driver with Level 1 basic tasks such as braking or steering or acceleration. One or more technologies for assisted driving, such as parking sensors or adaptive cruise control, are present in Level 1 automobiles. Like traditional driving control systems, adaptive driving control systems can change the speed of the vehicle and maintain safe stopping distances in addition to maintaining a predetermined speed. Despite the fact that this feature might slow down a car, a driver must remain vigilant and manage brake pressure in accordance with the information at hand. Parking sensors sound a warning when they identify an object in the driver’s parking route. Although this is intended to help drivers, the automobile must still be physically moved when parking. A large percentage of the vehicles we encounter on the road today have Level 1 driving automation.

The second-level advanced driver assistance systems can only control limited tasks such as braking, steering, and acceleration, so they must interact with the driver to make decisions based on road conditions. Vehicles at the second level have two or more simultaneous assisted driving technologies. For instance, a Level 2 car can adjust its acceleration and steering on the highway according to the speed of the traffic in front of it. These cars can only drive themselves in specific situations.

At the third level, it is capable of handling driving activities most of the time, but a handler is still necessary to be able to take control of the vehicle when required. Thus, the exceptional scenarios are handled by the human driver. Audi’s AI traffic jam pilot is an illustration of conditional automation. When a traffic jam is encountered, the system has the ability to step in and move slowly through it. When the road is clear, the vehicle signals the driver to take control again because the conditions for autonomous operation are no longer met. Under specific circumstances, the car merely keeps an eye on its surroundings; in all other situations, the driver is responsible.

At the fourth level, the ADS of the vehicle is open to handle all the driving tasks by itself in circumstances where the attention and interaction of humans are not necessary. Complete automation is incorporated in Level 5, where the ADS of the vehicles is capable of handling every task in all circumstances without the need for human driver assistance. The 5G technology will take AV to the next level by enabling full automation by allowing AVs to communicate not only with fellow vehicles but also with traffic lights, roads, and signage; hence, complete automation will be made possible.

### 3.2.3 History of Artificial Intelligence in Driverless Cars

The first production car, dubbed the “Benz Patent-Motorwagen,” was created in 1885 by Karl Benz in Mannheim, Germany, and it included a gasoline-powered internal combustion engine. Ever since the inception of the Benz Patent-Motorwagen, people wanted cars to go autonomous. In 1925, Francis Houdina, the inventor, operated a remote-controlled unmanned vehicle on the streets of Manhattan. The radio had the ability to start the engine, blow the horn, and shift gears. There was a display of the first self-driving vehicle created by General Motors. The metal spikes on the road assisted in the functioning of the electric vehicle that was being steered by radio-controlled EM fields.

In the 1960s, proponents of AI started to imagine autonomous cars that could drive through regular streets. Reverse-engineering the necessary systems similar to those found in a moving animal posed enormous problems that included sensing, processing, and reacting. With the technology available to them, the first and the last steps were possible. Processing, the machine intelligence required in between them, was the unknown component. It can be very deadly when a vehicle’s AI confuses a human in the road with the puddle reflection alongside. Several teams were competing in 2004 for $1 million by the US DARPA for attaining the dream in by 2015, the US military vehicles one-third will be automated. The initial batch of 15 competitors failed badly, making it only a short distance from the planned 227-km race before colliding. That was not the case the next time around. The Mojave Desert in California was traversed by an odd armada of driverless cars and trucks without a scratch the next year in which the autonomous robotic automobile “Stanley” from the Stanford University Racing Team took First Place. This team was mentored by the director of Stanford AI Laboratory and associate professor of CS department, Sebastian Thrun, and was a victory in the use of ML. Stanley was well versed in machine learning algorithm integration with sensors that helped it recognize impediments and avoid them while maintaining its course. By 2007, the Urban Challenge had expanded those accomplishments to a fictitious urban setting. The foundation for self-driving had been created by European experts, but the United States was now a strong competitor. The disparity was caused by several things that include better radar and laser sensors, as well as upgraded software for road following and collision prevention. Also helpful was good mapping. Animals are better at analyzing their environments than robots are, but a car that is always aware of its surroundings can concentrate on several variables. After leading the Stanford University racing team to win the DARPA Grand Challenge in 2005, Thrun led Google’s self-driving car project and became Waymo in 2016.

To bring complete autonomous driving to the masses, Waymo made great benefit of AI. Engineers from the firm and the Google Brain team worked together to integrate deep neural network (DNN) into their pedestrian detection system. Proposed in the 1960s, DNNs, also known as deep neural learning, is part of a broader area of artificial intelligence. DNNs are more complex and abstract than smaller neural networks, allowing them to learn high-level features \[[4](https://learning-oreilly-com.ezproxy.christchurchcitylibraries.com/library/view/artificial-intelligence-for/9781119847465/c01.xhtml#ref4)\]. With the help of DNN, engineers were able to cut pedestrian identification errors in half using deep learning techniques. More than 10 million kilometers of road training and hundreds of millions of interactions involving pedestrians, cyclists, and cars have been integrated into Waymo’s deep learning modular training program. It is recorded by Waymo that it has traveled in an autonomous mode more than 10 billion miles in simulation as part of the company’s deep learning training.

### 3.2.4 Advancements Over the Years

Like any previous automotive breakthrough, it took a while for this technology to develop to the point where it is now. The autonomous vehicle concept is the result of intense work by a number of educational institutions and research scholars, as well as big giant automobile companies. It is similar to how cruise control, ABS, and airbags, as well as today’s advanced emergency braking (AEB), were all developed.

A new system for the AV test vehicle of Continental was developed by experts from the industry like Siemens and technical universities in Darmstadt and Munich. To standardize testing, the Continental created an autonomous vehicle in 1969. To the shock of the onlookers, Continental’s first electronically controlled driverless vehicle made its debut on the Lüneburg Heath Contidrom test track on 11 September 1968. This car was directed by the conductor wire in the lane of the road’s surface. The vehicle’s sensors in the electronics system allowed it to determine whether it was still on course and automatically changed the steering as necessary. Hans-Jürgen Meyer said, “In the end, it was a wire-driven automobile.” The engineers fitted several cutting-edge pieces of technology in the Mercedes-Benz 250 automatic with electromechanical steering, throttle valve controller, and radio system for transmitting measurements. There were numerous antennas in the bumper, and the control electronics and electro-pneumatic braking system were in the trunk. The control station next to the test track delivered instructions to the car _via_ wires telling it to accelerate or honk its horns or brake.

At the Tsukuba Mechanical Engineering Laboratory in Japan, S. Tsugawa and his colleagues created the first truly autonomous vehicle in 1977. This car was capable of processing images of the road in front of it and was self-driving. It had two cameras and processed signals using analog computer technology. It was capable of recognizing white street markings when traveling at a speed of 33 km per hour. The concept of self-driving automobiles really got its start with this advancement in the realm of vehicular automation. Then, many major automakers began making an effort to develop autonomous vehicles \[[5](https://learning-oreilly-com.ezproxy.christchurchcitylibraries.com/library/view/artificial-intelligence-for/9781119847465/c01.xhtml#ref5)\].

University of Munich researcher Ernst Dickmanns first began working independently on AVs in the 1980s. He purchased a Mercedes van and filled it to the brim with electronics. The VaMoRs, or “Versuchsfahrzeug für autonomous mobilität und Rechnerseh,” was the name of this vehicle that translates to “test car for self-driving and computer vision.” It was outfitted with 16-bit Intel logic chips, as well as a number of additional sensing devices and software that help it to identify anything on the road. While being tested on the German Autobahn, it went about 20 miles at a speed of over 90 km per hour, with 96 km per hour top speed. The main invention of Dickmanns was the aptly named “dynamic vision,” which allowed the imaging system to exclude irrelevant noise and concentrate exclusively on pertinent items. The VaMoRs trial piqued Daimler’s interest in Dickmanns’ work. He was given the opportunity to work with €800 million that is over a billion dollars when adjusted for inflation as part of the EUREKA Prometheus Project to create the VaMP, a Mercedes-Benz W140 500 SEL with the VaMoRs’ autonomous driving technologies installed. The VITA-2 was the identical twin of the VaMP.

The largest research and development initiative ever undertaken in the realm of autonomous cars was the Eureka PROMETHEUS. Here, €749 million in funding was received from EUREKA Member States. This pan-European effort included participation from numerous colleges and automakers. VaMP, developed after 7 years of VaMoRs, used two cameras to process 320 × 240-pixel images at a distance of 100 m to discern lane markers, their correlative positioning in the lane, and the prevalence of other automobiles. During a trial run close to Paris, VaMP managed to navigate traffic and speed to 130 km per hour while detecting the right time to switch lanes. The following year, Dickmanns’ team traveled 1,600 km in a Mercedes S-Class between Munich and Denmark speeding up to 180 km per hour with “approximately 95% of the distance…traveled totally automatically,” according to Dickmanns.

The DARPA Grand Challenge that was held for the first time was held in the United States in the Mojave Desert and announced on 30 July 2002 was approved by the US Congress and offered a $1 million prize with the goal of reducing ground warfare by one-third. Vehicles were used by the military until 2015. The Carnegie Mellon University Red Team covered the farthest distance, covering 11.9 km out of the planned 227 km, although none of the cars managed to cover the entire distance. As a result, no team could win because they could only cover 5% of the total distance. In June of that same year, the next grand challenge with a little over 200 km off-road course and a $2 million reward was announced by DARPA in the year 2004, which was twice as much as the first. The 23 final contestants performed in October 2005 with the benefit of lessons learned and upgraded cars. The tough course included three tunnels, a steep pass with precipitous drop-offs, and over 100 twists and turns. With a winning time of 6 h 53 min, the Stanford Racing Team took home the $2 million prize, followed by the Carnegie Mellon Red Team. Five teams in all finished the contest. As the goal of the competition was to create a vehicle that could detect oncoming obstacles and track GPS waypoints, it was announced as one of the cornerstones of implementing autonomous driving. These developments sparked curiosity and creativity, and the results were pleasing to herald the next challenge. In May 2006, the Defense Department revealed the Urban Challenge, the third in the sequence of challenges. It occurred on 3 November 2007 at the California location formerly known as George AFB Victorville. The goal of this competition, which built on the success of the Grand Challenges in 2004 and 2005, was to create a vehicle that could operate in traffic without a human driver and handle challenging circumstances including parking, passing, and navigating intersections. As the first instance in which autonomous cars and human-driven cars have interacted in traffic in an urban setting, this occurrence was both singular and absolutely revolutionary. With a 97-km urban circuit, the competition was more difficult this time. With an average speed of 22.5 km per hour over the course of 6 h in a difficult metropolitan region, Tartan Racing’s “Boss” from Carnegie Mellon University triumphed. According to Mr. Tony Tether, the director of DARPA, autonomous vehicle technology is reliable and will inevitably protect lives both on and off the road. Teams of participants were sponsored by major manufacturers and technology companies like GM, VW, Caterpillar, Continental AG, Intel, Google, and others.

The first transcontinental driving test route was undertaken by the VisLab at the University of Parma. It began on 20 July 2010, in Parma, and ended on 28 October 2010, in Shanghai, encompassing 15,926 km through nine different nations. The scientific findings of the VisLab Intercontinental Autonomous Challenge (VIAC), which involved driving photovoltaic electric vehicles across more than 13,000-km distance, will serve as the first examples of autonomous driving. These exacting tests offer a comprehensive evaluation of the technology being developed. The system is tested in various settings to see how it performs under various circumstances. At the conclusion of the excursion, the data will be used for further lab analysis. This expedition consists of four autonomous vehicles, which includes two traveling vehicles and two backup vehicles plus a non-autonomous support vehicle \[[6](https://learning-oreilly-com.ezproxy.christchurchcitylibraries.com/library/view/artificial-intelligence-for/9781119847465/c01.xhtml#ref6)\].

As described in [Figure 3.1](https://learning-oreilly-com.ezproxy.christchurchcitylibraries.com/library/view/artificial-intelligence-for/9781119847465/c01.xhtml#fig3-1), when the leader is visible, the cars take a leader-follower method, where the follower precisely follows the leader’s trajectory while fine-tuning its road lane position is taken care by sensing locally using various technologies including image selection and KLT tracking. GPS data are used to define the route when the leader is concealed or too far away for the following to see it. The car also has a radio for inter-vehicle communication, GPS, and an IMU. Additionally, the vehicle has a solar panel that can provide enough electricity to properly all of the systems in the vehicle. Each vehicle has three personal computers (PCs), two of which handle sensor data and one of which has a world model that receives messages from the other two PCs. The optimal maneuver, and consequently the best trajectory, is chosen from the synthetic model in order to complete the chosen mission \[[7](https://learning-oreilly-com.ezproxy.christchurchcitylibraries.com/library/view/artificial-intelligence-for/9781119847465/c01.xhtml#ref7)\]. The BRAiVE experience-based sensor is used as a suit, with the exception of an extra laser scanner that is used particularly for off-road driving and is positioned to frame the ground. Additionally, the vehicle has V2V, GPS, and IMU communication systems. The car’s roof is an inertial as well as a GPS-like gadget powered by TopCon AGI3. The Egnos/WAAS adjustment is used by the GPS to attain an accuracy of roughly 1 m. IMU comprises gyroscopes, accelerometers, and magnetometers of axes 3 and 2, respectively. The VIAC until this date is the most tested self-driving project, traveling 13,000 km across several nations, i.e., from the land of Italy to far China, which came to an end on 28 October 2010 \[[8](https://learning-oreilly-com.ezproxy.christchurchcitylibraries.com/library/view/artificial-intelligence-for/9781119847465/c01.xhtml#ref8)\].

![[attachments/fig3-1.jpg]]

[**Figure 3.1**](https://learning-oreilly-com.ezproxy.christchurchcitylibraries.com/library/view/artificial-intelligence-for/9781119847465/c01.xhtml#rfig3-1) System architecture for selecting the leader car.

The primary distinction of the usual AV tests and VIAC tests, demonstrations, or agility testing, such as the VIAC and DARPA, was able to cross usual roads under common circumstances and that regarding traffic, road conditions, or adherence to traffic laws is not considered and assumed \[[7](https://learning-oreilly-com.ezproxy.christchurchcitylibraries.com/library/view/artificial-intelligence-for/9781119847465/c01.xhtml#ref7)\].

According to a Google report from September 2016, since the project’s 2009 launch, it has traveled more than 3.38 million kilometers \[[9](https://learning-oreilly-com.ezproxy.christchurchcitylibraries.com/library/view/artificial-intelligence-for/9781119847465/c01.xhtml#ref9)\]. Back in 2005, Stanford won its $2 million prize in DARPA challenge with the help of Sebastian Thrun, the former director of Stanford AI lab and a coinventor of Google Street View and who served as the principal investigator of the projects. Sebastian Thrun, who eventually ended his tenure in the company with an idea to launch his own businesses, was succeeded by Chris Urmson, who later oversaw the team. In August 2016, Mr. Urmson also departed the project \[[10](https://learning-oreilly-com.ezproxy.christchurchcitylibraries.com/library/view/artificial-intelligence-for/9781119847465/c01.xhtml#ref10)\].

### 3.2.5 Driverless Cars and the Technology they are Built Upon

| **Serial number** | **Name** | **Year** | **Testing platform** | **Technology used** |
| --- | --- | --- | --- | --- |
| 1 | The Continental Contidrom | 1969 | Mercedes-Benz 250 Automatic | Electromechanical steering |
| Electromechanical throttle control |
| Radio system for reporting measurements |
| Electro-pneumatic braking system |
| 2 | Tsukuba Mechanical Engineering | 1977 |   | Analog computer technology |
| 3 | VaMoRs | 1986 | Mercedes-Benz van | Saccadic Vision |
| Kalman Filters |
| Parallel Computers |
| 16-bit Intel Microprocessor |
| 4 | The EUREKA PROMETHEUS project | 1987–1995 | Mercedes-Benz W140 500 SEL | PIMM1 integrated processors |
| Mathematical morphology ASIC developed by the CMM |
| Temporal dynamic morphological filter (TDF) |
| PROLAB2 |
| EMS-Vision autonomy system |
| 5 | Team Stanford Racing from DARPA Grand Challenge | 2005 | Modified Volkswagen Touareg R5 named Stanley | Pentium M computers |
| 6DOF measurement unit for inertia |
| Range finding with the help of laser |
| 24GHz Radio Detection And Ranging system |
| A pair of stereo camera |
| Single eye type - vision system |
| Global Positioning System |
| 6 | VisLab Intercontinental Autonomous Challenge | 2010 | Piaggio Porter Electric Power | BRAiVE platform |
| X-BY-WIRE SYSTEM |
| Laser Scanner |
| V2V communication System |
| IMU |
| Global Positioning System |
| Panoramic camera system |
| LiDAR |
| GOLD framework |
| Felisa and Zani road position detection system |
| VisLab designed Calibration tools and procedures |
| 7 | Waymo LLC | 2009 - Present | Chrysler Pacifica Hybrid minivan, Jaguar I-Pace and Class 8 truck Daimler’s Freightliner Cascadia, Modified Toyota Priuses, Lexus SUVs, Custombuilt prototype vehicle named Firefly, | TensorFlow |
| TPUs |
| SurfelGAN |
| LiDARs |
| Sensor fusion technology |
| Deep Neural Networks (DNNs) |
| Center Prediction Neural Network (CPNN) |
| Object Property Neural Network (OPNN) |
| AutoML |
| NAS |
| CNNs |

### 3.2.6 Advancement of Algorithms

Using an image processing technique in 1979, an experimental Stanford Cart that used the Cart’s Vision Algorithm was able to move around on its own in a small environment. This algorithm, which was modeled after the Blocks World planning technique, was shown to be ineffective when used outdoors even though it effectively downgraded images as edges set, where there were numerous complex forms and colors \[[11](https://learning-oreilly-com.ezproxy.christchurchcitylibraries.com/library/view/artificial-intelligence-for/9781119847465/c01.xhtml#ref11)\]. However, one of the most well-known techniques in artificial intelligence planning \[[12](https://learning-oreilly-com.ezproxy.christchurchcitylibraries.com/library/view/artificial-intelligence-for/9781119847465/c01.xhtml#ref12)\] and environment recognition is the 1960 Blocks World method.

The first autonomous car capable of traveling a predetermined area was the experimental VaMP vehicle in 1995, covering more than a thousand kilometers without human aid. The prototype of the EMS-Vision autonomous system could drive through traffic and past cars—thanks to data collected from bifocal camera systems mounted on biaxial platforms. Maps of the road network, waypoints on the map that were static objects, and statistics were all employed by EMS-Vision. The EMS-Vision is a sophisticated system that can continually configure itself throughout the operation in response to the current situation and also has specialized modules for road recognition, attention control, navigation, and vehicle control \[[13](https://learning-oreilly-com.ezproxy.christchurchcitylibraries.com/library/view/artificial-intelligence-for/9781119847465/c01.xhtml#ref13)\]. The EMS-Vision system discussed above excludes advancements made after 1995; however, it does show the complexity and volume of algorithms used, which are meant as specified actions necessary to complete certain tasks in AV systems \[[11](https://learning-oreilly-com.ezproxy.christchurchcitylibraries.com/library/view/artificial-intelligence-for/9781119847465/c01.xhtml#ref11)\].

The culmination of parallel lines at a single position in three-dimensional space gives crucial information for recognizing roadways, much as the parallel lines that make up a lane meet at a single point in a two-dimensional picture. Identifying a road lane involves looking for lines that confluence at a specific location. By detecting the predominant picture section orientations, C. Rasmussen proposed the Vanishing Point method in the first place (640 × 480-pixel images are divided into 72 segments), predicting the location of the intersection point and then succeeding picture frames after that point. Today, this method, developed to locate the road in a desert area, is essential for identifying lanes of the road in a picture and forms the basis for more complex algorithms.

Machine learning can be used for labeling specific regions of an image according to what’s being shown, and an example of it is the full-resolution residual networks (FRRNs). This is hardly used in practice because of the high computing cost and the numerous artifacts produced \[[14](https://learning-oreilly-com.ezproxy.christchurchcitylibraries.com/library/view/artificial-intelligence-for/9781119847465/c01.xhtml#ref14)\]. With the introduction of specialized equipment and new quicker techniques for semantic segmentation, this strategy might alter. Machine vision is used to identify particular picture properties that were determined earlier, including moving objects, traffic lanes, barriers, and distance estimation. Road signs, traffic lights, and other road markers can all be recognized by specialized Advanced Driver Assistance Systems (ADAS) \[[15](https://learning-oreilly-com.ezproxy.christchurchcitylibraries.com/library/view/artificial-intelligence-for/9781119847465/c01.xhtml#ref15)\]. To reliably detect road signs and other visual features, three types of algorithms are used: general machine learning algorithms, artificial neural networks, and deep machine learning. These methods arose from multiple studies and were reported in scientific journals. The SVM approaches are the most widely used and thoroughly studied techniques for identifying road signs. AdaBoost is known for its quick execution times, while neural network techniques are the slowest. Deep machine learning techniques might be challenging to implement in ADAS systems due to their high-technology requirements. R-CNN that runs more quickly might be an alternative for semantic image segmentation \[[16](https://learning-oreilly-com.ezproxy.christchurchcitylibraries.com/library/view/artificial-intelligence-for/9781119847465/c01.xhtml#ref16)\].

The initial choice made by an autonomous vehicle is the route (path) to the destination, which is typically dependent on variables like distance, travel time, or estimated fuel consumption. The Bellman-Ford algorithm, which is constrained by the requirement to define non-negative weighted edges, constraint, the Dijkstra algorithm, which can be used if the topology of roads is known, and the 1968 A\* algorithm, along with its modifications, are examples of heuristic algorithms that take into account the criterion of travel \[[17](https://learning-oreilly-com.ezproxy.christchurchcitylibraries.com/library/view/artificial-intelligence-for/9781119847465/c01.xhtml#ref17)\].

### 3.2.7 Case Study on Tesla

The year 2003 saw the founding of the American electric car manufacturer Tesla by Elon Musk, Marc Tarpenning, JB Straubel, Ian Wright, and Martin Eberhard. The production of EVs with lithium-ion batteries is Tesla’s area of expertise. Tesla, a forerunner in the utilization of renewable energy for generating sustainable clean energy for vehicle propulsion, is establishing a firm platform for the expansion of the EV market. Unlike traditional vehicles that are primarily reliant on using fossil fuels to power their engines, this approach is more ecologically responsible. From its very founding in 2003, Tesla has had tremendous market growth mostly as a result of its leadership in the EV sector development of cutting-edge technology innovation. Tesla not long ago became a member of the Trillion Dollar Club, which has only been attained by a select few businesses. The rise of the electric vehicle sector is being aided by government policies and efforts, which has a positive impact on the worldwide market. The internal combustion of gas, which occurs in conventional fossil fuel-powered vehicles, is what contributes to the production of greenhouse gases that harm the environment. However, an EV uses a motor that is powered by electricity from a source that keeps the current at a specified value regardless of the load condition, and this source is named the current source, thus helping in the reduction of overall pollution. Countries around the world including the United States and China have imposed various regulations and laws to protect their environment. The use of EVs is greatly supported by initiatives taken by various organizations like the California Air Resources Board (CARB). The aim to increase the adoption of electrical vehicles is supported globally by three primary pillars: the government’s initial fleet purchase, purchasing EVs at a lower selling price as a result of regional and nationwide incentives, and the law that forces automobile manufacturers to begin selling a certain number of EVs from the year 2019. As a result of the synchronic alignment with the environmental goal of the government, Tesla has substantial backing from the government. EVs are generally known to increase the energy security and quality of air as the carbon dioxide emissions are very well lower than that of conventional vehicles. Under the Bush administration’s advanced technology vehicle manufacturing program, Tesla originally obtained a loan, which it later promised to repay with no interest. Tesla has received governmental backing in the form of many state subsidies in addition to a federal loan. For instance, additional income tax credits are now being provided by several states for each Tesla purchase. These incentives eventually became a crucial part of Tesla’s business model and its EV advertising campaigns. Tesla’s stock price increased by over $12 billion USD, demonstrating that the company’s financial performance is closely tied to government-granted privilege and that political preferences are given more weight than delivering value to customers \[[18](https://learning-oreilly-com.ezproxy.christchurchcitylibraries.com/library/view/artificial-intelligence-for/9781119847465/c01.xhtml#ref18)\].

Automobile makers are now focusing more on developing electric automobiles than traditional ones, which encourages the development of EV in the automotive sector. In the automobile business, EVs provide a significant amount of advantages over internal combustion vehicles. For example, energy can be employed to naturally powered EVs. Alternatively, conventional vehicles that are propelled by the burning of gasoline use up oil, an exhaustible natural resource. Additionally, gas is more costly than electricity. In order to supply the energy needed for the car to run while it is moving, electrical vehicles use regenerative braking. As a result, they are substantially less expensive than gas-powered automobiles, often costing only one-third as much \[[18](https://learning-oreilly-com.ezproxy.christchurchcitylibraries.com/library/view/artificial-intelligence-for/9781119847465/c01.xhtml#ref18)\].

A form of rechargeable battery called a lithium-ion battery is used to power electric vehicles and portable electronics. Akira Yoshino originally created a prototype Li-ion battery in 1985, and Sony and Asahi later improved on it to produce a commercial Li-ion battery. In the past, the usage of lithium-ion batteries was widespread in the EV market \[[19](https://learning-oreilly-com.ezproxy.christchurchcitylibraries.com/library/view/artificial-intelligence-for/9781119847465/c01.xhtml#ref19)\]. Even though researchers are developing replacement technologies for Li-ion batteries, the International Energy Agency (IEA) still predicts that the Li-ion battery will remain to be the industry standard for the next few years in the EV market. In the meantime, Tesla is the only firm able to use battery cells in the shape of a cylinder in its battery packs to lower the price of a cylinder battery cell greater than 158 USD per kWh \[[20](https://learning-oreilly-com.ezproxy.christchurchcitylibraries.com/library/view/artificial-intelligence-for/9781119847465/c01.xhtml#ref20)\]. Tesla employs sophisticated engineering techniques along with the creation of more gigafactories to make it a reality. Thus, it is safe to say that Tesla has therefore transformed the battery sectors by producing battery cells in the shape of a cylinder to make it more cost-efficient to be used in battery packs. Due to Tesla’s enviable position as the undisputed leader in the worldwide EV industry, other automakers claim they would invest huge amounts of money to overtake Tesla. Established firms like Toyota and Panasonic have begun to merge horizontally along with the recognized EV sector in order to create and build more potent battery packs to propel the EVs. Furthermore, in an effort to increase the number of battery operations in Ohio, General Motors and South Korea’s LG Chem have committed millions and millions of dollars to attempt to stay up with Tesla’s production of powerful batteries.

The price-to-earnings (P/E) ratio signifies the correlation between the change in stock price and earnings. The company’s future gains and growth can be greatly known by analyzing this metric. Tesla outperforms its competitors in the market with a significantly higher P/E ratio. A study on this supremacy inferred that there is a higher chance of Tesla stocks being overvalued, as, in the market, it is almost 12 times greater and constantly growing besides having a staggeringly low overall electric vehicle sales. In the year 2020, Tesla was the dominant force in the sector of automobiles, as it showed significant growth in P/E from the lowest to the highest ratio. The P/E ratio of Tesla greatly exceeds those of the other automotive sector P/E ratios; hence, making it stable enough to continuously outperform its competitors.

To conclude, Tesla keeps expanding abroad to hasten the uptake of sustainable energy production and transportation worldwide. Political, economic, social and technological (PEST) perspectives claim that Tesla has received a lot of support in order to expand its impact globally. Due to its monopolistic market domination and technological advancements, Tesla has an advantage over its rivals in terms of how it views market rivalry and crucial technology. These characteristics increase the likelihood that shareholders will be upbeat about Tesla’s future growth, which might increase Tesla’s real market value. The results of the numerous valuation techniques employed in this study clearly demonstrated that the true market rate for Tesla is still exorbitant, proving that the share price is excessive.

## 3.3 Conclusion

In conclusion, even if autonomous vehicles appear to be a distant concern for present road users, global tests of vehicles in motion indicate that public cars may soon be available. Another revolution similar to those of the DARPA Grand Challenge will undoubtedly result in changes in transportation, so it is critical to inform the public about how to handle autonomous vehicles. This instruction should cover proper conduct on the roadways where the vehicles would be able to move. However, it is crucial to educate the general public with the applied nomenclature and the division of vehicles owing to the degree of autonomous driving before cars are fully integrated in the existing transportation systems. This will make it easier for society to learn about a new mode of transportation that, although it may currently appear abstract, represents the transportation of the future.

## References

1.  1\. Hong, D., Kimmel, S., Boehling, R., Camoriano, N., Cardwell, W., Jannaman, G., Purcell, A., Ross, D., Russel, E., Development of a semi-autonomous vehicle operable by the visually-impaired, in: _IEEE International Conference on Multisensor Fusion and Integration for Intelligent Systems_, MFI, pp. 539–544, 20082008.
2.  2\. Litman, T., _Autonomous vehicle implementation predictions_, Victoria Transport Policy Institute 28, Victoria, British Columbia, Canada, 2015.
3.  3\. Manyika, J., Chui, M., Bughin, J., Dobbs, R., Bisson, P., Marrs, A., _Disruptive technologies: Advances that will transform life, business, and the global economy_, McKinsey Global Institute, New York, 2013.
4.  4\. Sze, V., Chen, Y.-H., Yang, T.-J., Emer, J.S., Efficient processing of deep neural networks: A tutorial and survey, in: _Proceedings of the IEEE_, vol. 105, pp. 2295–2329, Dec. 2017, doi: 10.1109/JPROC.2017.2761740.
5.  5\. Bhat, A., Autonomous vehicles: A perspective of past and future trends, 2017.
6.  6\. Broggi, A., Cerri, P., Felisa, M., Laghi, M., Mazzei, L., Porta, P.P., The VisLab intercontinental autonomous challenge: An extensive test for a platoon of intelligent vehicles. _Int. J. Veh. Auton. Syst._, 4, 1185, 2012, 10. 10.1504/ IJVAS.2012.051250.
7.  7\. Bertozzi, M., Bombini, L., Broggi, A., Buzzoni, M., Cardarelli, E., Cattani, S., Cerri, P., Debattisti, S., Fedriga, R., Felisa, M., Gatti, L., Giacomazzo, A., Grisleri, P., Laghi, M., Mazzei, L., Medici, P., Panciroli, M., Porta, P.P., Zani, P., The VisLab intercontinental autonomous challenge: 13,000 km, 3 months, no driver, 2010.
8.  8\. Broggi, A., Bombini, L., Cattani, S., Cerri, P., Fedriga, R., II, Sensing requirements for a 13,000 km intercontinental autonomous drive. _2010 IEEE Intelligent Vehicles Symposium_, pp. 500–505, 2010, doi: 10.1109/ IVS.2010.5548026.
9.  9\. Hongyu, H., Chi, Z., Yuhuan, S., Bin, Z., Fei, G., An improved artificial potential field model considering vehicle velocity for autonomous driving. _IFAC-PapersOnLine_, 51, 31, 1, 2018.
10.  10\. Maddodi, S. and Prasad, K., Recent advances in technological innovations in IT, management, education & social sciences. _An Evol. Auton. Vehicle-A Case Study Waymo_, Oct. 2019.
11.  11\. Bugała, M., Algorithms applied in autonomous vehicle systems, 2018.
12.  12\. Gupta, N. and Dana, S.N., On the complexity of blocks-world planning. _Artif. Intell._, 56, Elsevier, 2, 1992.
13.  13\. Gregor, R., Lutzeler, M., Pellkofer, M., Siedersberger, K.-H., Dickmanns, E.D., EMS-Vision: A perceptual system for autonomous vehicles. _IEEE Trans. Intell. Transp. Syst._, 3, 1, 48–59, March 2002.
14.  14\. Rasmussen, C., Grouping dominant orientations or Ill-structured road following. _International Conference on Computer Vision and Pattern Recognition_, IEEE, 2004.
15.  15\. Li, L., Wen, D., Zheng, N.-N., Shen, L.-C., Cognitive cars: A new frontier for ADAS research. _IEEE Trans. Intell. Transp. Syst._, 13, 1, 395–407, March 2012, doi: 10.1109/TITS.2011.2159493.
16.  16\. Mukhometzianov, R. and Wang, Y., Review. Machine learning techniques for traffic sign detection, 4, 2017.
17.  17\. Ibarra, O.H. and Kim, C.E., Heuristic algorithms for scheduling independent tasks on nonidentical processors. _J. ACM_, 24, 2, 280–289, 1977.
18.  18\. Liu, S., Competition and valuation: A case study of tesla motors. _IOP Conference Series: Earth and Environmental Science_, vol. 692, p. 022103, 2021, 10.1088/1755-1315/692/2/022103.
19.  19\. Blomgren, G.E., The development and future of lithium ion batteries. _J. Electrochem. Soc._, 164, A5019, 2017.
20.  20\. Drexhagen, P., Tesla: A tech company selling cars-a story-driven valuation? _Diss._, 2021, [https://doi-org.ezproxy.christchurchcitylibraries.com/10362/122665](https://doi-org.ezproxy.christchurchcitylibraries.com/10362/122665).

## Note

1.  [\*](https://learning-oreilly-com.ezproxy.christchurchcitylibraries.com/library/view/artificial-intelligence-for/9781119847465/c01.xhtml#rcor1)_Corresponding author_: [amcse@tce.edu.amcse@tce.edu](mailto:amcse@tce.edu.amcse@tce.edu); ORCID: 0000-0002-3324-5317